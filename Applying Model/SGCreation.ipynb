{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Twitter](https://x.com/dec1costello) | [GitHub](https://github.com/dec1costello) | [Kaggle](https://www.kaggle.com/dec1costello) | [LinkedIn](https://www.linkedin.com/in/declan-costello-7423aa137/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Key Principles</b><br>\n",
    "    - This notebook models Expected Strokes Gained across various lies.<br>\n",
    "    - It then evaluates performance by comparing predicted values with actual outcomes to derive Strokes Gained.<br>\n",
    "    - Finally, enirched Strokes Gained statistics are generated to provide deeper insights into player performance.<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Context**\n",
    "1. [Installation](#Installation)\n",
    "2. [Data Import](#Data-Import)\n",
    "3. [Model Import](#Model-Import)\n",
    "4. [xS Predictions](#xS-Predictions)\n",
    "5. [xS Aggregation](#xS-Aggregation)\n",
    "6. [SG Calculation](#SG-Calculation)\n",
    "7. [SG Enrichment](#SG-Enrichment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š **Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='category_encoders.base_contrast_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“‚ **Data Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv(\"FE_golf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– **Model Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved compressed approach model\n",
    "with bz2.BZ2File('approachModel.joblib.bz2', 'rb') as f:\n",
    "    approachModel = joblib.load(f)\n",
    "\n",
    "#load saved compressed putting model\n",
    "with bz2.BZ2File('puttingModel.joblib.bz2', 'rb') as f:\n",
    "    puttingModel = joblib.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **â›³ Expected Strokes Predctions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **OTT xS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the per-player summed hole scores\n",
    "player_hole_score = (\n",
    "    result_df.loc[result_df['shot'] == 1]\n",
    "    .groupby(['player_id', 'round', 'hole'])['hole_score']\n",
    "    .sum()\n",
    "    .groupby(['hole', 'round'])\n",
    "    .mean()\n",
    "    .rename('xS_OTT')\n",
    ")\n",
    "\n",
    "# Map it back to result_df\n",
    "result_df = result_df.merge(player_hole_score.reset_index(), on=['hole', 'round'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Approach xS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize xS column\n",
    "result_df['xS_A'] = 0.0  \n",
    "\n",
    "# Dynamically extract feature columns (excluding the target column 'xS_G')\n",
    "feature_cols = [col for col in result_df.columns if col != 'xS_A']\n",
    "\n",
    "# Extract the feature matrix for the conditionally filtered rows\n",
    "X_input = result_df.loc[result_df['from_location_scorer'] != 'Green', feature_cols].copy()\n",
    "\n",
    "# Predict only for rows where 'from_location_scorer' is an approach shot\n",
    "result_df.loc[result_df['from_location_scorer'] != 'Green', 'xS_A'] = approachModel.predict(X_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Putting xS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize xS column\n",
    "result_df['xS_G'] = 0.0  \n",
    "\n",
    "# Dynamically extract feature columns (excluding the target column 'xS_G')\n",
    "feature_cols = [col for col in result_df.columns if col != 'xS_G']\n",
    "\n",
    "# Extract the feature matrix for the conditionally filtered rows\n",
    "X_input = result_df.loc[result_df['from_location_scorer'] == 'Green', feature_cols].copy()\n",
    "\n",
    "# Predict only for rows where 'from_location_scorer' is 'Green'\n",
    "result_df.loc[result_df['from_location_scorer'] == 'Green', 'xS_G'] = puttingModel.predict(X_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Expected Strokes Aggregation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **True xS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new 'xS' column based on 'from_location_scorer'\n",
    "result_df['xS_True'] = np.where(\n",
    "    result_df['from_location_scorer'] == 'Tee Box', result_df['xS_OTT'], \n",
    "    np.where(\n",
    "        result_df['from_location_scorer'] == 'Green', result_df['xS_G'], \n",
    "        result_df['xS_A']\n",
    "    )\n",
    ")\n",
    "\n",
    "result_df['xS_True'] = np.maximum(result_df['xS_True'], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Raw xS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['xS_Raw'] = np.where(\n",
    "        result_df['from_location_scorer'] == 'Green', result_df['xS_G'], \n",
    "        result_df['xS_A']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Strokes Gained Calculation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **True SG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is sorted correctly\n",
    "result_df = result_df.sort_values(by=['player_id', 'round', 'hole', 'shot'])\n",
    "\n",
    "# Compute xS_next using shift within each hole\n",
    "result_df['xS_true_next'] = result_df.groupby(['player_id', 'round', 'hole'])['xS_True'].shift(-1)\n",
    "\n",
    "# Identify last shot in each hole (where there's no next shot)\n",
    "last_shot_mask = result_df['xS_true_next'].isna()\n",
    "\n",
    "# Compute strokes gained\n",
    "result_df['SG_True'] = (result_df['xS_True'] - result_df['xS_true_next']) - 1\n",
    "\n",
    "# Special case for last shot in a hole\n",
    "result_df.loc[last_shot_mask, 'SG_True'] = result_df.loc[last_shot_mask, 'xS_True'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Raw SG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is sorted correctly\n",
    "result_df = result_df.sort_values(by=['player_id', 'round', 'hole', 'shot'])\n",
    "\n",
    "# Compute xS_next using shift within each hole\n",
    "result_df['xS_raw_next'] = result_df.groupby(['player_id', 'round', 'hole'])['xS_Raw'].shift(-1)\n",
    "\n",
    "# Identify last shot in each hole (where there's no next shot)\n",
    "last_shot_mask = result_df['xS_raw_next'].isna()\n",
    "\n",
    "# Compute strokes gained\n",
    "result_df['SG_Raw'] = (result_df['xS_Raw'] - result_df['xS_raw_next']) - 1\n",
    "\n",
    "# Special case for last shot in a hole\n",
    "result_df.loc[last_shot_mask, 'SG_Raw'] = result_df.loc[last_shot_mask, 'xS_Raw'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Strokes Gained Enrichment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chunk SG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['SG_Raw_Chunk'] = result_df['xS_Raw'] - result_df['strokes_to_hole_out']\n",
    "result_df['SG_True_Chunk'] = result_df['xS_True'] - result_df['strokes_to_hole_out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **True SG per Hole**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['SG_True_per_Hole'] = result_df['xS_OTT'] - result_df['hole_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rolling True SG Totals per Shot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['SG_True_Rolling_per_Shot_per_Hole_per_Round'] = result_df.groupby(['last_name','round', 'hole'])['SG_True'].cumsum() # how each shot affects the total score for each hole in a round\n",
    "result_df['SG_True_Rolling_per_Shot'] = result_df.groupby(['last_name'])['SG_True'].cumsum() #how each shot affects the total score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SG Percentiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 50, 100, 150, 200, float('inf')]\n",
    "labels = ['50-0', '100-50', '150-100', '200-150', '200+']\n",
    "\n",
    "# Apply binning to the DataFrame\n",
    "result_df['SG_bins'] = pd.cut(result_df['distance_to_pin'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Fill missing values with empty string\n",
    "result_df['SG_bins'] = result_df['SG_bins'].cat.add_categories([''])\n",
    "result_df['SG_bins'] = result_df['SG_bins'].fillna('')\n",
    "# df['SG_bins'] = df['SG_bins'].cat.add_categories(['Green', 'Tee Box'])\n",
    "result_df['SG_bins'] = result_df['SG_bins'].cat.add_categories(['Putting', 'OTT'])\n",
    "\n",
    "# df.loc[df['from_location_scorer'] == 'Green', 'SG_bins'] = 'Green'\n",
    "# df.loc[df['from_location_scorer'] == 'Tee Box', 'SG_bins'] = 'Tee Box'\n",
    "result_df.loc[result_df['from_location_scorer'] == 'Green', 'SG_bins'] = 'Putting'\n",
    "result_df.loc[result_df['from_location_scorer'] == 'Tee Box', 'SG_bins'] = 'OTT'\n",
    "\n",
    "result_df['SG_True_binned_percentile'] = result_df.groupby(['par_value', 'SG_bins','round'], observed=False)['SG_True'].rank(pct=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“© **Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('SG.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
